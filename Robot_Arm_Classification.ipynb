{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucinoGarcia/Robot-Arm-Classification/blob/main/Robot_Arm_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_z9Jg8s3YRK",
        "outputId": "4aaa3d2e-7b9a-4e37-ad47-ac5fbe7d8d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gesture Data"
      ],
      "metadata": {
        "id": "IDCHlqck3e8s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ONNeW36j0p"
      },
      "source": [
        "### Gesture 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NewChannelDataRow = 0\n",
        "G1_Data = np.zeros([911, 625, 16])    # G1 has 911 samples\n",
        "All_G1 = np.zeros([0, 250, 16])\n",
        "\n",
        "for session in range(1, 4):\n",
        "  Rows = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/Gesture 1/DataBySession/ScriptTimes, Session \"+str(session)+\".csv\").iloc[:, 1]\n",
        "  Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/Gesture 1/DataBySession/Gesture 1, Session \"+str(session)+\".csv\")\n",
        "\n",
        "  for row in Rows:\n",
        "    for Channel in range(16):\n",
        "      G1_Data[NewChannelDataRow, :, Channel] = Data.iloc[:, Channel][int(row):(int(row)+625)]\n",
        "    NewChannelDataRow += 1\n",
        "\n",
        "\n",
        "G1_Data = G1_Data*(8388608/187500)                                     # To scale the Gesture 1 Data into the same range as the other gestures\n",
        "\n",
        "G1_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G1_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G1_CutValues)) if G1_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G1_Data = np.delete(G1_Data, i, axis=0)\n",
        "  del G1_CutValues[i]\n",
        "\n",
        "G1_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G1_CutValues]\n",
        "\n",
        "\n",
        "for sample in range(len(G1_Data)):\n",
        "  All_G1 = np.concatenate((All_G1, [G1_Data[sample, G1_CutValues[sample]:((G1_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "'''\n",
        "fig, axs = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        index = i * 4 + j\n",
        "\n",
        "        for k in range(All_G1.shape[0]):\n",
        "            axs[i, j].plot(All_G1[k, :, index], color='blue', alpha=0.05)  # Adjust alpha for transparency\n",
        "\n",
        "        axs[i, j].set_title(f'Plot {index+1}')\n",
        "        axs[i, j].set_xlabel('Points')\n",
        "        axs[i, j].set_ylabel('Data')\n",
        "\n",
        "fig.suptitle('Gesture 1, Segmented')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "del axs, fig, i, j, index, k\n",
        "'''\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G1_Data, NewChannelDataRow, G1_CutValues, Rows, i, row, sample, session"
      ],
      "metadata": {
        "id": "h_MDVT_SrJcL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdEvYyeU6oy6"
      },
      "source": [
        "### Gesture 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qvnA4myc6oy7"
      },
      "outputs": [],
      "source": [
        "G2_Data = np.zeros([833, 625, 16])    # G2 has 833 samples\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 2\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 2/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G2_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "G2_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G2_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G2_CutValues)) if G2_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G2_Data = np.delete(G2_Data, i, axis=0)\n",
        "  del G2_CutValues[i]\n",
        "\n",
        "\n",
        "G2_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G2_CutValues]\n",
        "All_G2 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G2_Data)):\n",
        "  All_G2 = np.concatenate((All_G2, [G2_Data[sample, G2_CutValues[sample]:((G2_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G2_CutValues, G2_Data, files, folder, i, row, sample, subfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjzJ5sg6o7x"
      },
      "source": [
        "### Gesture 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G3_Data = np.zeros([980, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 3\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 3/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G3_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "G3_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G3_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G3_CutValues)) if G3_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G3_Data = np.delete(G3_Data, i, axis=0)\n",
        "  del G3_CutValues[i]\n",
        "\n",
        "\n",
        "G3_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G3_CutValues]\n",
        "All_G3 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G3_Data)):\n",
        "  All_G3 = np.concatenate((All_G3, [G3_Data[sample, G3_CutValues[sample]:((G3_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G3_CutValues, G3_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "nWHIxl8xw-Tr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfU6_R4f6pHo"
      },
      "source": [
        "### Gesture 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G4_Data = np.zeros([1016, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 4\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 4/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G4_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "\n",
        "G4_CutValues = [int(i) for i in list(pd.concat([pd.read_csv(\"/content/drive/MyDrive/G4_Cuts_1.txt\", header=None),\n",
        "                                          pd.read_csv(\"/content/drive/MyDrive/G4_Cuts_2.txt\", header=None).iloc[:, 700:]], axis=1).iloc[0, :])]\n",
        "\n",
        "\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G4_CutValues)) if G4_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G4_Data = np.delete(G4_Data, i, axis=0)\n",
        "  del G4_CutValues[i]\n",
        "\n",
        "\n",
        "G4_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G4_CutValues]\n",
        "All_G4 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G4_Data)):\n",
        "  All_G4 = np.concatenate((All_G4, [G4_Data[sample, G4_CutValues[sample]:((G4_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G4_CutValues, G4_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "JR7O586Iyjnl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJhYS4GY1QbH"
      },
      "source": [
        "### Gesture 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G0_Data = np.zeros([502, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 0\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 0/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G0_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "All_G0 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G0_Data)):\n",
        "  All_G0 = np.concatenate((All_G0, [G0_Data[sample, :250, :], G0_Data[sample, 250:500, :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, G0_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "R_0JD-dh7UC8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk9zeWqwtNv6"
      },
      "source": [
        "# Filtering and Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-AmvKkkRtMVB"
      },
      "outputs": [],
      "source": [
        "def butter_lowpass_filter(data, cutoff_freq=50, sampling_rate=125, order=4):\n",
        "    nyquist = 0.5 * sampling_rate\n",
        "    normal_cutoff = cutoff_freq / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    filtered_data = lfilter(b, a, data, axis=0)\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Labels\n",
        "\n",
        "MinSamp = np.min([len(All_G1), len(All_G2), len(All_G3), len(All_G4), len(All_G0)])\n",
        "All_Data = np.concatenate((butter_lowpass_filter(All_G1[:MinSamp, :, :]), butter_lowpass_filter(All_G2[:MinSamp, :, :]),\n",
        "                           butter_lowpass_filter(All_G3[:MinSamp, :, :]), butter_lowpass_filter(All_G4[:MinSamp, :, :]),\n",
        "                           butter_lowpass_filter(All_G0[:MinSamp, :, :])), axis=0)\n",
        "All_Labels = np.concatenate((np.ones([1, MinSamp]), np.ones([1, MinSamp])*2, np.ones([1, MinSamp])*3, np.ones([1, MinSamp])*4,\n",
        "                             np.ones([1, MinSamp])*0), axis=1).T\n",
        "\n",
        "del All_G0, All_G1, All_G2, All_G3, All_G4, MinSamp"
      ],
      "metadata": {
        "id": "fvdNw5IFvzuM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfKQUxqCxciH"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LzUZiI-Oxnlf"
      },
      "outputs": [],
      "source": [
        "#label_as_binary = LabelBinarizer()\n",
        "#All_Labels = label_as_binary.fit_transform(All_Labels)\n",
        "\n",
        "All_Labels = to_categorical(All_Labels, num_classes=5)    # encoded labels\n",
        "\n",
        "In_Train, In_Test, Out_Train, Out_Test =  train_test_split(All_Data, All_Labels, test_size = 0.2, random_state=321)\n",
        "\n",
        "# CNN accepts 3 dimentional data so we are going to reshape() our data\n",
        "In_Train = In_Train.reshape(In_Train.shape[0], 250, 16, 1)\n",
        "In_Test = In_Test.reshape(In_Test.shape[0], 250, 16, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b89yI5vox6OD",
        "outputId": "02bc1a14-d5fb-4643-9a3e-20aceea5f9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 248, 14, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 124, 7, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 5, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 61, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7808)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               999552    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1019013 (3.89 MB)\n",
            "Trainable params: 1019013 (3.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "CNN = Sequential()\n",
        "\n",
        "CNN.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape = In_Train[0].shape))\n",
        "\n",
        "CNN.add(MaxPool2D(pool_size=(2, 2)))\n",
        "CNN.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "CNN.add(MaxPool2D(pool_size=(2, 2)))\n",
        "CNN.add(Flatten())\n",
        "\n",
        "CNN.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "CNN.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVttLp_PJhmY",
        "outputId": "f57de9a9-f7dd-47d5-a392-19d9be917dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "68/68 [==============================] - 15s 149ms/step - loss: 291361.0000 - accuracy: 0.6984 - val_loss: 1026.8635 - val_accuracy: 0.6904\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 8s 118ms/step - loss: 618.4182 - accuracy: 0.7487 - val_loss: 161.0819 - val_accuracy: 0.6569\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 364.9265 - accuracy: 0.6923 - val_loss: 298.7867 - val_accuracy: 0.6318\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 147.8058 - accuracy: 0.6862 - val_loss: 80.4520 - val_accuracy: 0.6318\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 9s 140ms/step - loss: 83.5872 - accuracy: 0.7179 - val_loss: 93.1546 - val_accuracy: 0.7071\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 7s 109ms/step - loss: 80.5481 - accuracy: 0.7753 - val_loss: 122.4521 - val_accuracy: 0.6987\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 10s 144ms/step - loss: 565.9720 - accuracy: 0.7291 - val_loss: 650.4689 - val_accuracy: 0.6067\n"
          ]
        }
      ],
      "source": [
        "trainingEpochs = CNN.fit(In_Train, Out_Train, batch_size=32, epochs=7, validation_split=0.1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IDCHlqck3e8s",
        "dl2c6OA60c-A",
        "IfKQUxqCxciH",
        "2IvHKHeZowH_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}