{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_z9Jg8s3YRK",
        "outputId": "920284dc-4b14-49df-ae50-27a081940219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "from scipy.signal import butter, lfilter\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gesture Data"
      ],
      "metadata": {
        "id": "IDCHlqck3e8s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ONNeW36j0p"
      },
      "source": [
        "### Gesture 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NewChannelDataRow = 0\n",
        "G1_Data = np.zeros([911, 625, 16])    # G1 has 911 samples\n",
        "All_G1 = np.zeros([0, 250, 16])\n",
        "\n",
        "for session in range(1, 4):\n",
        "  Rows = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/Gesture 1/DataBySession/ScriptTimes, Session \"+str(session)+\".csv\").iloc[:, 1]\n",
        "  Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/Gesture 1/DataBySession/Gesture 1, Session \"+str(session)+\".csv\")\n",
        "\n",
        "  for row in Rows:\n",
        "    for Channel in range(16):\n",
        "      G1_Data[NewChannelDataRow, :, Channel] = Data.iloc[:, Channel][int(row):(int(row)+625)]\n",
        "    NewChannelDataRow += 1\n",
        "\n",
        "\n",
        "G1_Data = G1_Data*(8388608/187500)                                     # To scale the Gesture 1 Data into the same range as the other gestures\n",
        "\n",
        "G1_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G1_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G1_CutValues)) if G1_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G1_Data = np.delete(G1_Data, i, axis=0)\n",
        "  del G1_CutValues[i]\n",
        "\n",
        "G1_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G1_CutValues]\n",
        "\n",
        "\n",
        "for sample in range(len(G1_Data)):\n",
        "  All_G1 = np.concatenate((All_G1, [G1_Data[sample, G1_CutValues[sample]:((G1_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "'''\n",
        "fig, axs = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        index = i * 4 + j\n",
        "\n",
        "        for k in range(All_G1.shape[0]):\n",
        "            axs[i, j].plot(All_G1[k, :, index], color='blue', alpha=0.05)  # Adjust alpha for transparency\n",
        "\n",
        "        axs[i, j].set_title(f'Plot {index+1}')\n",
        "        axs[i, j].set_xlabel('Points')\n",
        "        axs[i, j].set_ylabel('Data')\n",
        "\n",
        "fig.suptitle('Gesture 1, Segmented')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "del axs, fig, i, j, index, k\n",
        "'''\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G1_Data, NewChannelDataRow, G1_CutValues, Rows, i, row, sample, session"
      ],
      "metadata": {
        "id": "h_MDVT_SrJcL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdEvYyeU6oy6"
      },
      "source": [
        "### Gesture 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qvnA4myc6oy7"
      },
      "outputs": [],
      "source": [
        "G2_Data = np.zeros([833, 625, 16])    # G2 has 833 samples\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 2\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 2/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G2_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "G2_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G2_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G2_CutValues)) if G2_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G2_Data = np.delete(G2_Data, i, axis=0)\n",
        "  del G2_CutValues[i]\n",
        "\n",
        "\n",
        "G2_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G2_CutValues]\n",
        "All_G2 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G2_Data)):\n",
        "  All_G2 = np.concatenate((All_G2, [G2_Data[sample, G2_CutValues[sample]:((G2_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G2_CutValues, G2_Data, files, folder, i, row, sample, subfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjzJ5sg6o7x"
      },
      "source": [
        "### Gesture 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G3_Data = np.zeros([980, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 3\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 3/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G3_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "G3_CutValues = [int(i) for i in list(pd.read_csv(\"/content/drive/MyDrive/G3_Cuts.txt\", header=None).iloc[0, :])]\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G3_CutValues)) if G3_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G3_Data = np.delete(G3_Data, i, axis=0)\n",
        "  del G3_CutValues[i]\n",
        "\n",
        "\n",
        "G3_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G3_CutValues]\n",
        "All_G3 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G3_Data)):\n",
        "  All_G3 = np.concatenate((All_G3, [G3_Data[sample, G3_CutValues[sample]:((G3_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G3_CutValues, G3_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "nWHIxl8xw-Tr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfU6_R4f6pHo"
      },
      "source": [
        "### Gesture 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G4_Data = np.zeros([1016, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 4\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 4/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G4_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "\n",
        "G4_CutValues = [int(i) for i in list(pd.concat([pd.read_csv(\"/content/drive/MyDrive/G4_Cuts_1.txt\", header=None),\n",
        "                                          pd.read_csv(\"/content/drive/MyDrive/G4_Cuts_2.txt\", header=None).iloc[:, 700:]], axis=1).iloc[0, :])]\n",
        "\n",
        "\n",
        "\n",
        "DropTheseIndex = list(reversed([i for i in range(len(G4_CutValues)) if G4_CutValues[i] == 0]))\n",
        "for i in DropTheseIndex:\n",
        "  G4_Data = np.delete(G4_Data, i, axis=0)\n",
        "  del G4_CutValues[i]\n",
        "\n",
        "\n",
        "G4_CutValues = [0 if i == 50 else (375 if i > 375 else i) for i in G4_CutValues]\n",
        "All_G4 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G4_Data)):\n",
        "  All_G4 = np.concatenate((All_G4, [G4_Data[sample, G4_CutValues[sample]:((G4_CutValues[sample])+250), :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, DropTheseIndex, G4_CutValues, G4_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "JR7O586Iyjnl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJhYS4GY1QbH"
      },
      "source": [
        "### Gesture 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G0_Data = np.zeros([502, 625, 16])\n",
        "\n",
        "\n",
        "for folder, subfolders, files in os.walk(os.path.abspath(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 0\")):\n",
        "  row = 0\n",
        "  for i in files:\n",
        "      Data = pd.read_csv(\"/content/drive/MyDrive/BME Capstone/All Gestures/Gesture 0/\"+i, header=None, dtype=object)\n",
        "      for Channel in range(16):\n",
        "        G0_Data[row, :, Channel] = Data.iloc[:, Channel]\n",
        "      row += 1\n",
        "\n",
        "All_G0 = np.empty((0, 250, 16))\n",
        "\n",
        "for sample in range(len(G0_Data)):\n",
        "  All_G0 = np.concatenate((All_G0, [G0_Data[sample, :250, :], G0_Data[sample, 250:500, :]]), axis=0)\n",
        "\n",
        "\n",
        "del Channel, Data, G0_Data, files, folder, i, row, sample, subfolders"
      ],
      "metadata": {
        "id": "R_0JD-dh7UC8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk9zeWqwtNv6"
      },
      "source": [
        "# Filtering and Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-AmvKkkRtMVB"
      },
      "outputs": [],
      "source": [
        "def butter_lowpass_filter(data, cutoff_freq=50, sampling_rate=125, order=4):\n",
        "    nyquist = 0.5 * sampling_rate\n",
        "    normal_cutoff = cutoff_freq / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    filtered_data = lfilter(b, a, data, axis=0)\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Labels\n",
        "\n",
        "MinSamp = np.min([len(All_G1), len(All_G2), len(All_G3), len(All_G4), len(All_G0)])\n",
        "All_Data = np.concatenate((butter_lowpass_filter(All_G1[:MinSamp, :, :]), butter_lowpass_filter(All_G2[:MinSamp, :, :]),\n",
        "                           butter_lowpass_filter(All_G3[:MinSamp, :, :]), butter_lowpass_filter(All_G4[:MinSamp, :, :]),\n",
        "                           butter_lowpass_filter(All_G0[:MinSamp, :, :])), axis=0)\n",
        "All_Labels = np.concatenate((np.ones([1, MinSamp]), np.ones([1, MinSamp])*2, np.ones([1, MinSamp])*3, np.ones([1, MinSamp])*4,\n",
        "                             np.ones([1, MinSamp])*0), axis=1).T\n",
        "\n",
        "del All_G0, All_G1, All_G2, All_G3, All_G4, MinSamp"
      ],
      "metadata": {
        "id": "fvdNw5IFvzuM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfKQUxqCxciH"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "All_Data = np.load(\"All_Data.npy\")\n",
        "All_Labels = np.load(\"All_Labels.npy\")"
      ],
      "metadata": {
        "id": "lYYzprdfLTdk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LzUZiI-Oxnlf"
      },
      "outputs": [],
      "source": [
        "All_Labels = to_categorical(All_Labels, num_classes=5)\n",
        "In_Train, In_Test, Out_Train, Out_Test =  train_test_split(All_Data, All_Labels, test_size = 0.2, random_state=321)\n",
        "\n",
        "# CNN accepts 3 dimentional data\n",
        "In_Train = In_Train.reshape(In_Train.shape[0], 250, 16, 1)\n",
        "In_Test = In_Test.reshape(In_Test.shape[0], 250, 16, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b89yI5vox6OD",
        "outputId": "4eb0a852-4dd2-4555-cc9a-66fd637eeb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 248, 14, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 124, 7, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 5, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 61, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7808)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               999552    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1019013 (3.89 MB)\n",
            "Trainable params: 1019013 (3.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "CNN = Sequential()\n",
        "\n",
        "CNN.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape = In_Train[0].shape))\n",
        "\n",
        "CNN.add(MaxPool2D(pool_size=(2, 2)))\n",
        "CNN.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "CNN.add(MaxPool2D(pool_size=(2, 2)))\n",
        "CNN.add(Flatten())\n",
        "\n",
        "CNN.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "CNN.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVttLp_PJhmY",
        "outputId": "585ef925-d88e-4211-81df-8952a840a081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "68/68 [==============================] - 24s 325ms/step - loss: 227680.9062 - accuracy: 0.7469 - val_loss: 1763.7485 - val_accuracy: 0.7699\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 13s 188ms/step - loss: 2263.5847 - accuracy: 0.7972 - val_loss: 787.1883 - val_accuracy: 0.7657\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 17s 245ms/step - loss: 1075.6500 - accuracy: 0.8000 - val_loss: 493.6936 - val_accuracy: 0.7573\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 14s 210ms/step - loss: 1893.7679 - accuracy: 0.7786 - val_loss: 383.0010 - val_accuracy: 0.7197\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 14s 205ms/step - loss: 2986.1743 - accuracy: 0.7762 - val_loss: 884.4761 - val_accuracy: 0.7531\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 18s 270ms/step - loss: 1085.7446 - accuracy: 0.7776 - val_loss: 1759.1813 - val_accuracy: 0.7071\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 13s 189ms/step - loss: 1041.6101 - accuracy: 0.7678 - val_loss: 686.6398 - val_accuracy: 0.7071\n"
          ]
        }
      ],
      "source": [
        "trainingEpochs = CNN.fit(In_Train, Out_Train, batch_size=32, epochs=7, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(CNN.predict(In_Test), axis = 1)\n",
        "Out_Test = np.argmax(Out_Test, axis=1)\n",
        "cm = confusion_matrix(Out_Test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKFy3r5rG90x",
        "outputId": "adad9abd-fdc3-45b2-89ca-71d628dbc51e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 3s 163ms/step\n",
            "[[103   0   0   3  10]\n",
            " [  0 111   0   1   0]\n",
            " [  0  52  65   0   0]\n",
            " [  2  27   1  92   0]\n",
            " [  5  58   4   1  61]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IDCHlqck3e8s",
        "dl2c6OA60c-A",
        "IfKQUxqCxciH",
        "2IvHKHeZowH_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}